{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ../input/timm-pytorch-image-models/pytorch-image-models-master/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "import cv2\n",
    "import yaml\n",
    "import timm\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import albumentations as album\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from utils import seed_everything\n",
    "from easydict import EasyDict as edict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_SAMPLE_RATE = 32_000\n",
    "\n",
    "BIRD_CODE = {\n",
    "    'acafly': 0, 'acowoo': 1, 'aldfly': 2, 'ameavo': 3, 'amecro': 4, 'amegfi': 5, 'amekes': 6, 'amepip': 7, 'amered': 8,\n",
    "    'amerob': 9, 'amewig': 10, 'amtspa': 11, 'andsol1': 12, 'annhum': 13, 'astfly': 14, 'azaspi1': 15, 'babwar': 16,\n",
    "    'baleag': 17, 'balori': 18, 'banana': 19, 'banswa': 20, 'banwre1': 21, 'barant1': 22, 'barswa': 23, 'batpig1': 24,\n",
    "    'bawswa1': 25, 'bawwar': 26, 'baywre1': 27, 'bbwduc': 28, 'bcnher': 29, 'belkin1': 30, 'belvir': 31, 'bewwre': 32,\n",
    "    'bkbmag1': 33, 'bkbplo': 34, 'bkbwar': 35, 'bkcchi': 36, 'bkhgro': 37, 'bkmtou1': 38, 'bknsti': 39, 'blbgra1': 40,\n",
    "    'blbthr1': 41, 'blcjay1': 42, 'blctan1': 43, 'blhpar1': 44, 'blkpho': 45, 'blsspa1': 46, 'blugrb1': 47, 'blujay': 48,\n",
    "    'bncfly': 49, 'bnhcow': 50, 'bobfly1': 51, 'bongul': 52, 'botgra': 53, 'brbmot1': 54, 'brbsol1': 55, 'brcvir1': 56, \n",
    "    'brebla': 57, 'brncre': 58, 'brnjay': 59, 'brnthr': 60, 'brratt1': 61, 'brwhaw': 62, 'brwpar1': 63, 'btbwar': 64, \n",
    "    'btnwar': 65, 'btywar': 66, 'bucmot2': 67, 'buggna': 68, 'bugtan': 69, 'buhvir': 70, 'bulori': 71, 'burwar1': 72, \n",
    "    'bushti': 73, 'butsal1': 74, 'buwtea': 75, 'cacgoo1': 76, 'cacwre': 77, 'calqua': 78, 'caltow': 79, 'cangoo': 80, \n",
    "    'canwar': 81, 'carchi': 82, 'carwre': 83, 'casfin': 84, 'caskin': 85, 'caster1': 86, 'casvir': 87, 'categr': 88, \n",
    "    'ccbfin': 89, 'cedwax': 90, 'chbant1': 91, 'chbchi': 92, 'chbwre1': 93, 'chcant2': 94, 'chispa': 95, 'chswar': 96, \n",
    "    'cinfly2': 97, 'clanut': 98, 'clcrob': 99, 'cliswa': 100, 'cobtan1': 101, 'cocwoo1': 102, 'cogdov': 103, 'colcha1': 104, \n",
    "    'coltro1': 105, 'comgol': 106, 'comgra': 107, 'comloo': 108, 'commer': 109, 'compau': 110, 'compot1': 111, 'comrav': 112, \n",
    "    'comyel': 113, 'coohaw': 114, 'cotfly1': 115, 'cowscj1': 116, 'cregua1': 117, 'creoro1': 118, 'crfpar': 119, 'cubthr': 120, \n",
    "    'daejun': 121, 'dowwoo': 122, 'ducfly': 123, 'dusfly': 124, 'easblu': 125, 'easkin': 126, 'easmea': 127, 'easpho': 128, \n",
    "    'eastow': 129, 'eawpew': 130, 'eletro': 131, 'eucdov': 132, 'eursta': 133, 'fepowl': 134, 'fiespa': 135, 'flrtan1': 136, \n",
    "    'foxspa': 137, 'gadwal': 138, 'gamqua': 139, 'gartro1': 140, 'gbbgul': 141, 'gbwwre1': 142, 'gcrwar': 143, 'gilwoo': 144, \n",
    "    'gnttow': 145, 'gnwtea': 146, 'gocfly1': 147, 'gockin': 148, 'gocspa': 149, 'goftyr1': 150, 'gohque1': 151, 'goowoo1': 152, \n",
    "    'grasal1': 153, 'grbani': 154, 'grbher3': 155, 'grcfly': 156, 'greegr': 157, 'grekis': 158, 'grepew': 159, 'grethr1': 160, \n",
    "    'gretin1': 161, 'greyel': 162, 'grhcha1': 163, 'grhowl': 164, 'grnher': 165, 'grnjay': 166, 'grtgra': 167, 'grycat': 168, \n",
    "    'gryhaw2': 169, 'gwfgoo': 170, 'haiwoo': 171, 'heptan': 172, 'hergul': 173, 'herthr': 174, 'herwar': 175, 'higmot1': 176, \n",
    "    'hofwoo1': 177, 'houfin': 178, 'houspa': 179, 'houwre': 180, 'hutvir': 181, 'incdov': 182, 'indbun': 183, 'kebtou1': 184, \n",
    "    'killde': 185, 'labwoo': 186, 'larspa': 187, 'laufal1': 188, 'laugul': 189, 'lazbun': 190, 'leafly': 191, 'leasan': 192, \n",
    "    'lesgol': 193, 'lesgre1': 194, 'lesvio1': 195, 'linspa': 196, 'linwoo1': 197, 'littin1': 198, 'lobdow': 199, 'lobgna5': 200, \n",
    "    'logshr': 201, 'lotduc': 202, 'lotman1': 203, 'lucwar': 204, 'macwar': 205, 'magwar': 206, 'mallar3': 207, 'marwre': 208, \n",
    "    'mastro1': 209, 'meapar': 210, 'melbla1': 211, 'monoro1': 212, 'mouchi': 213, 'moudov': 214, 'mouela1': 215, 'mouqua': 216, \n",
    "    'mouwar': 217, 'mutswa': 218, 'naswar': 219, 'norcar': 220, 'norfli': 221, 'normoc': 222, 'norpar': 223, 'norsho': 224, \n",
    "    'norwat': 225, 'nrwswa': 226, 'nutwoo': 227, 'oaktit': 228, 'obnthr1': 229, 'ocbfly1': 230, 'oliwoo1': 231, 'olsfly': 232, \n",
    "    'orbeup1': 233, 'orbspa1': 234, 'orcpar': 235, 'orcwar': 236, 'orfpar': 237, 'osprey': 238, 'ovenbi1': 239, 'pabspi1': 240, \n",
    "    'paltan1': 241, 'palwar': 242, 'pasfly': 243, 'pavpig2': 244, 'phivir': 245, 'pibgre': 246, 'pilwoo': 247, 'pinsis': 248, \n",
    "    'pirfly1': 249, 'plawre1': 250, 'plaxen1': 251, 'plsvir': 252, 'plupig2': 253, 'prowar': 254, 'purfin': 255, 'purgal2': 256, \n",
    "    'putfru1': 257, 'pygnut': 258, 'rawwre1': 259, 'rcatan1': 260, 'rebnut': 261, 'rebsap': 262, 'rebwoo': 263, 'redcro': 264, \n",
    "    'reevir1': 265, 'rehbar1': 266, 'relpar': 267, 'reshaw': 268, 'rethaw': 269, 'rewbla': 270, 'ribgul': 271, 'rinkin1': 272, \n",
    "    'roahaw': 273, 'robgro': 274, 'rocpig': 275, 'rotbec': 276, 'royter1': 277, 'rthhum': 278, 'rtlhum': 279, 'ruboro1': 280, \n",
    "    'rubpep1': 281, 'rubrob': 282, 'rubwre1': 283, 'ruckin': 284, 'rucspa1': 285, 'rucwar': 286, 'rucwar1': 287, 'rudpig': 288, \n",
    "    'rudtur': 289, 'rufhum': 290, 'rugdov': 291, 'rumfly1': 292, 'runwre1': 293, 'rutjac1': 294, 'saffin': 295, 'sancra': 296, \n",
    "    'sander': 297, 'savspa': 298, 'saypho': 299, 'scamac1': 300, 'scatan': 301, 'scbwre1': 302, 'scptyr1': 303, 'scrtan1': 304, \n",
    "    'semplo': 305, 'shicow': 306, 'sibtan2': 307, 'sinwre1': 308, 'sltred': 309, 'smbani': 310, 'snogoo': 311, 'sobtyr1': 312, \n",
    "    'socfly1': 313, 'solsan': 314, 'sonspa': 315, 'soulap1': 316, 'sposan': 317, 'spotow': 318, 'spvear1': 319, 'squcuc1': 320, \n",
    "    'stbori': 321, 'stejay': 322, 'sthant1': 323, 'sthwoo1': 324, 'strcuc1': 325, 'strfly1': 326, 'strsal1': 327, 'stvhum2': 328, \n",
    "    'subfly': 329, 'sumtan': 330, 'swaspa': 331, 'swathr': 332, 'tenwar': 333, 'thbeup1': 334, 'thbkin': 335, 'thswar1': 336, \n",
    "    'towsol': 337, 'treswa': 338, 'trogna1': 339, 'trokin': 340, 'tromoc': 341, 'tropar': 342, 'tropew1': 343, 'tuftit': 344, \n",
    "    'tunswa': 345, 'veery': 346, 'verdin': 347, 'vigswa': 348, 'warvir': 349, 'wbwwre1': 350, 'webwoo1': 351, 'wegspa1': 352, \n",
    "    'wesant1': 353, 'wesblu': 354, 'weskin': 355, 'wesmea': 356, 'westan': 357, 'wewpew': 358, 'whbman1': 359, 'whbnut': 360, \n",
    "    'whcpar': 361, 'whcsee1': 362, 'whcspa': 363, 'whevir': 364, 'whfpar1': 365, 'whimbr': 366, 'whiwre1': 367, 'whtdov': 368, \n",
    "    'whtspa': 369, 'whwbec1': 370, 'whwdov': 371, 'wilfly': 372, 'willet1': 373, 'wilsni1': 374, 'wiltur': 375, 'wlswar': 376, \n",
    "    'wooduc': 377, 'woothr': 378, 'wrenti': 379, 'y00475': 380, 'yebcha': 381, 'yebela1': 382, 'yebfly': 383, 'yebori1': 384, \n",
    "    'yebsap': 385, 'yebsee1': 386, 'yefgra1': 387, 'yegvir': 388, 'yehbla': 389, 'yehcar1': 390, 'yelgro': 391, 'yelwar': 392, \n",
    "    'yeofly1': 393, 'yerwar': 394, 'yeteup1': 395, 'yetvir': 396, 'nocall': 397\n",
    "}\n",
    "\n",
    "INV_BIRD_CODE = {v: k for k, v in BIRD_CODE.items()}\n",
    "\n",
    "DATA_DIR = Path('/kaggle/input/birdclef-2021')\n",
    "LOG_DIR = Path('/kaggle/input/exp-001-20210407091109-0682/')\n",
    "\n",
    "TEST = (len(list((DATA_DIR / \"test_soundscapes/\").glob(\"*.ogg\"))) != 0)\n",
    "if TEST:\n",
    "    AUDIO_DIR = Path(DATA_DIR / \"test_soundscapes\")\n",
    "else:\n",
    "    AUDIO_DIR = Path(DATA_DIR / \"train_soundscapes\")\n",
    "\n",
    "DEVICE= torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conf:\n",
    "    duration = 5\n",
    "    sampling_rate = 32_000\n",
    "    n_fft = 2048\n",
    "    hop_length = 512\n",
    "    n_mels = 128\n",
    "    fmin = 20\n",
    "    fmax = sampling_rate // 2\n",
    "    power = 2.0\n",
    "    samples = sampling_rate * duration\n",
    "\n",
    "\n",
    "def get_transforms(params: Dict):\n",
    "    def get_object(transform):\n",
    "        if hasattr(album, transform.name):\n",
    "            return getattr(album, transform.name)\n",
    "        else:\n",
    "            return eval(transform.name)\n",
    "\n",
    "    transforms = None\n",
    "    if params is not None:\n",
    "        transforms = [\n",
    "            get_object(transform)(**transform.params)\n",
    "            for name, transform in params.items()\n",
    "        ]\n",
    "        transforms = album.Compose(transforms)\n",
    "\n",
    "    return transforms\n",
    "\n",
    "\n",
    "def mono_to_color(X, mean=None, std=None, norm_max=None, norm_min=None, eps=1e-6):\n",
    "    # Stack X as [X,X,X]\n",
    "    X = np.stack([X, X, X], axis=-1)\n",
    "\n",
    "    # Standardize\n",
    "    mean = mean or X.mean()\n",
    "    std = std or X.std()\n",
    "    Xstd = (X - mean) / (std + eps)\n",
    "    _min, _max = Xstd.min(), Xstd.max()\n",
    "    norm_max = norm_max or _max\n",
    "    norm_min = norm_min or _min\n",
    "    if (_max - _min) > eps:\n",
    "        # Scale to [0, 255]\n",
    "        V = Xstd\n",
    "        V[V < norm_min] = norm_min\n",
    "        V[V > norm_max] = norm_max\n",
    "        V = 255 * (V - norm_min) / (norm_max - norm_min)\n",
    "        V = V.astype(np.uint8)\n",
    "    else:\n",
    "        # Just zero\n",
    "        V = np.zeros_like(Xstd, dtype=np.uint8)\n",
    "    return V\n",
    "\n",
    "\n",
    "class CustomTestDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, cfg: Dict):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.filenames = df[\"file_name\"].values\n",
    "        self.seconds = df[\"seconds\"].values\n",
    "        self.transforms = get_transforms(cfg.transforms)\n",
    "        self.y = None\n",
    "        self.prior_filename = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.filenames[idx]\n",
    "        seconds = self.seconds[idx]\n",
    "        path_name = str(AUDIO_DIR / filename)\n",
    "        \n",
    "        if filename == self.prior_filename:\n",
    "            y = self.y\n",
    "        else:\n",
    "            y, sr = librosa.load(path_name, sr=conf.sampling_rate)\n",
    "            self.y = y\n",
    "            self.prior_filename = filename\n",
    "\n",
    "        start_index = conf.sampling_rate * (seconds - 5)\n",
    "        end_index = conf.sampling_rate * seconds\n",
    "        y = y[start_index:end_index].astype(np.float32)\n",
    "\n",
    "        melspec = librosa.feature.melspectrogram(\n",
    "            y,\n",
    "            sr=conf.sampling_rate,\n",
    "            n_mels=conf.n_mels,\n",
    "            fmin=conf.fmin,\n",
    "            fmax=conf.fmax,\n",
    "        )\n",
    "        melspec = librosa.power_to_db(melspec).astype(np.float32)\n",
    "        image = mono_to_color(melspec)\n",
    "\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image=image)[\"image\"]\n",
    "\n",
    "        image = cv2.resize(image, (self.cfg.img_size.height, self.cfg.img_size.width))\n",
    "        image = image.transpose(2, 0, 1)\n",
    "        image = (image / 255.0).astype(np.float32)\n",
    "\n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gem(x, p=3, eps=1e-6):\n",
    "    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
    "\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM,self).__init__()\n",
    "        self.p = Parameter(torch.ones(1)*p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return gem(x, p=self.p, eps=self.eps)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + ', ' + 'eps=' + str(self.eps) + ')'\n",
    "    \n",
    "    \n",
    "layer_encoder = {\n",
    "    'GeM': GeM,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_classes: int,\n",
    "        model_name: str = \"resnet50\",\n",
    "        pooling_name: str = \"GeM\",\n",
    "        args_pooling: Optional[Dict] = None,\n",
    "    ):\n",
    "        super(CustomModel, self).__init__()\n",
    "\n",
    "        self.backbone = timm.create_model(model_name, pretrained=False)\n",
    "\n",
    "        final_in_features = list(self.backbone.children())[-1].in_features\n",
    "        self.backbone = nn.Sequential(*list(self.backbone.children())[:-2])\n",
    "\n",
    "        self.pooling = layer_encoder[pooling_name](**args_pooling)\n",
    "\n",
    "        self.act = nn.ReLU()\n",
    "        self.drop = nn.Dropout(p=0.5)\n",
    "        self.fc = nn.Linear(final_in_features, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.pooling(x)\n",
    "        x = x.view(len(x), -1)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df, cfg):\n",
    "    test_dataset = CustomTestDataset(df, cfg.data.test)\n",
    "    test_loader = DataLoader(test_dataset, **cfg.data.test.loader)\n",
    "\n",
    "    model = CustomModel(\n",
    "        model_name=cfg.model.backbone,\n",
    "        n_classes=cfg.model.n_classes,\n",
    "        **cfg.model.params\n",
    "    ).to(DEVICE)\n",
    "    model.load_state_dict(torch.load(str(LOG_DIR / 'weight_best.pt')))\n",
    "    \n",
    "    test_preds = np.zeros(\n",
    "        (\n",
    "            len(test_loader.dataset),\n",
    "            cfg.model.n_classes * cfg.data.test.tta.iter_num,\n",
    "        )\n",
    "    )\n",
    "    test_preds_tta = np.zeros(\n",
    "        (len(test_loader.dataset), cfg.model.n_classes)\n",
    "    )\n",
    "    \n",
    "    model.eval()\n",
    "    for t in range(cfg.data.test.tta.iter_num):\n",
    "        for i, images in enumerate(test_loader):\n",
    "            images = images.to(DEVICE)\n",
    "\n",
    "            preds = model(images)\n",
    "\n",
    "            start_batch_idx = i * test_loader.batch_size\n",
    "            end_batch_idx = (i + 1) * test_loader.batch_size\n",
    "\n",
    "            start_col_idx = t * cfg.model.n_classes\n",
    "            end_col_idx = (t + 1) * cfg.model.n_classes\n",
    "\n",
    "            test_preds[\n",
    "                start_batch_idx:end_batch_idx, start_col_idx:end_col_idx\n",
    "            ] = preds.sigmoid().cpu().detach().numpy()\n",
    "\n",
    "    for i in range(cfg.model.n_classes):\n",
    "        preds_col_idx = [\n",
    "            i + cfg.model.n_classes * j\n",
    "            for j in range(cfg.data.valid.tta.iter_num)\n",
    "        ]\n",
    "        test_preds_tta[:, i] = np.mean(\n",
    "            test_preds[:, preds_col_idx], axis=1\n",
    "        ).reshape(-1)\n",
    "    \n",
    "    return test_preds_tta\n",
    "\n",
    "\n",
    "def get_predict_labels(preds):\n",
    "    events = preds >= cfg.threshold\n",
    "    nocall_col = np.zeros((len(preds), 1)).astype(bool)\n",
    "    nocall_col[events.sum(1) == 0] = True\n",
    "    events = np.concatenate([events, nocall_col], axis=1)\n",
    "    \n",
    "    predict_labels = []\n",
    "    for i in range(len(events)):\n",
    "        event = events[i, :]\n",
    "        labels = np.argwhere(event).reshape(-1).tolist()\n",
    "        \n",
    "        row_labels = []\n",
    "        for label in labels:\n",
    "            row_labels.append(INV_BIRD_CODE[label])\n",
    "        predict_labels.append(\" \".join(row_labels))\n",
    "\n",
    "    return predict_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST:\n",
    "    test_df = pd.read_csv(DATA_DIR / \"test.csv\")\n",
    "    sub_df = pd.read_csv(DATA_DIR / \"sample_submission.csv\")\n",
    "else:\n",
    "    test_df = pd.read_csv(DATA_DIR / \"train_soundscape_labels.csv\")\n",
    "    sub_df = pd.read_csv(DATA_DIR / \"train_soundscape_labels.csv\", usecols=[\"row_id\"])\n",
    "    \n",
    "test_df[\"file_id\"] = test_df[\"audio_id\"].astype(str) + \"_\" + test_df[\"site\"]\n",
    "\n",
    "p = r\"^(.+)_\\d+.ogg\"\n",
    "all_test_audio = os.listdir(AUDIO_DIR)\n",
    "file_id2fname = {re.search(p, f).group(1): f for f in all_test_audio if re.search(p, f)}\n",
    "test_df[\"file_name\"] = test_df[\"file_id\"].map(file_id2fname)\n",
    "test_df.head()\n",
    "    \n",
    "\n",
    "with open(LOG_DIR / 'config.yml', 'r') as yf:\n",
    "    cfg = edict(yaml.safe_load(yf))\n",
    "    \n",
    "cfg.data.test.loader.batch_size = 16\n",
    "    \n",
    "seed_everything(cfg.seed)\n",
    "\n",
    "test_preds = predict(test_df, cfg)\n",
    "test_preds_labels = get_predict_labels(test_preds)\n",
    "sub_df[\"birds\"] = test_preds_labels\n",
    "\n",
    "sub_df.to_csv('submission.csv', index=False)\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df['birds'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
